# C/C++ 程序底层优化导论

本篇只讨论程序的常数级别优化而不考虑时间复杂度层级的优化。如果你希望了解降低程序/算法的时间复杂度，建议你学习大二的数据结构课程以及大三算法课程，甚至是了解 ACM。

## 时间复杂度/常数

如果你还不知道什么叫做”常数优化“或者”时间复杂度“优化，这里简要地口胡一下，已经会了的同志请略过。

时间复杂度指的是在相同的环境下算法的运行时间（或者执行的语句数、指令条数）与问题规模的函数关系，比如冒泡排序的时间复杂度是 $ O(n^2) $ ，因为其算法实现是两层 for 循环（for i=1 to n-1; for j=n downto i+1），其要执行的语句数/指令数是 $ \frac{n(n-1)}{2} $ 的倍数。时间复杂度的表达式中的大 O 表示函数的渐进上界，比如 $ \lim_{n\rightarrow\infin} \frac{n^2}{n(n-1)/2}=2 $，因此 $f(x)=n^2$ 是 $g(x)=\frac{n(n-1)}{2}$的数量级的渐进上界。由于实际上我们表示程序的运行时间会被 CPU、内存等一系列的因素影响，而这些不是函数的自变量，而是常数系数，因此我们明确地表示出时间复杂度的常数系数是不可能的。以及，对于类似$h(x)=n^2+n$这种函数，可以写成$n(n+1)$，其中的$+1$也是常数系数，也被忽略掉，所以进行约定后$O(h(x))=n^2$。

我们刚才简要地口胡了一下时间复杂度大概是什么，你已经发现我不停地提常数系数的问题。如果我们的程序存在一个时间复杂度更优秀的版本，那么我们采用这个版本就能够大幅提升程序的性能。但是实际的工程项目中我们往往无法改进算法的时间复杂度（但如果是学术前沿的恐怕是可以的），这个时候要优化程序的运行时间就要从常数系数下手。我刚才已经提到了常数系数产生的原因：CPU性能、内存性能、总线性能、以至于程序实现是否存在多余的不影响时间复杂度的循环/递归，以及对计算机硬件利用率比较低。其中计算机本身的性能我们可以通过半导体工业的发展（但是 Intel 天天挤牙膏）实现，其他的程序方面的问题就需要我们自己解决。

## 向量化

计算机程序被编译器编译为机器码，也就是一条一条的机器指令。CPU 作为中央处理单元，要负责执行一条一条的指令。指令包含运算指令、访存指令、跳转指令等类别。我们要充分利用计算机硬件，针对指令的优化是必不可少的。



其中对于运算指令，我们可能在代码中遇到这种：

```cpp
for (int i = 0; i < n; ++i) c[i] = a[i] * 10 + b[i] / 2;
```

这个 for 循环看起来很简单，我们可以简单地规约成：$\vec{c}=10\vec{a}+\frac{1}{2}\vec{b}$，也就是向量运算。向量运算的特征是，对于一个循环，其循环变量的循环顺序如何不影响结果。比如这样的一个循环：

```cpp
for (int i = 1; i <= n; ++i) s[i] = s[i - 1] + a[i];
```

这个循环表示的是 $s_i=\sum_{i=1}^{i}a_i$。如果我们改成这样：

```cpp
for (int i = n; i >= 1; --i) s[i] = s[i - 1] + a[i];
```

`s`数组的结果就错了，也就是说这个循环的正确性依赖于其循环变量的运算次序。也就是说，如果我想知道一个循环可不可以规约为向量运算，可以试一试倒转循环顺序（很多情况下都能检测出来）。

能规约为向量运算的，除了普通的算术逻辑运算外，条件判断也是可行的，比如：

```cpp
// c[i] 已经有了初始值
for (int i = 1; i <= n; ++i) if (a[i] != b[i]) c[i] = a[i] / b[i];
```

这种情况下 `c[i]` 的计算也是可以向量化的。

现在我们大概了解了什么循环能规约成向量计算问题，现在我们就来优化它：我们保持循环代码不变，只需要在 `gcc` 中打开`-O3`就能支持向量化指令，`icc` 中可以使用`-xHOST`等参数来打开 SSE、AVX 向量运算指令。CPU 所支持的向量运算指令，是指 CPU 原本只能同时做一次加法一次赋值，现在利用向量化可以同时进行 4、8、16 个变量的加法、赋值同时计算。也就是说，如果情况比较理想，向量化指令甚至能将程序性能提升 10 倍（毕竟同时进行多次运算。

## 访存优化

我们知道计算机存储器结构分为多级：寄存器、L1、L2、L3、内存、外存。

其中寄存器的速度最快，但单位价格最高（是触发器构成的），L1 速度要慢一些，L2 次之，L3 更次，内存则比较慢了（从内存调取一个数据块的时间可能是 CPU 时钟周期的几十几百倍），外存就更慢了（毕竟是肉眼可见的速度）。

一级缓存的工作模式是写缓冲模式。首先将内存划分为很多块，比如我们可以将块大小设置为 128B，然后用内存实际容量除以块大小就是

如果略过中间的多级高速缓存，CPU 就不得不每次向内存调取数据，而我们已经提到内存的访问与 CPU 的工作速度差距很大（这是成本所限），因此 CPU 就总是在等待内存操作从而限制了 CPU 的性能发挥。

## 跳转优化

如果你理解了刚才提到的访存优化，我们继续扩展这个话题。我们之前提到的访存指数据访存，也就是我们要从 RAM 中调取数据到二级缓存再到一级数据缓存再到寄存器。现在我们考虑机器指令，如果现在我们有一个大循环，假设这个大循环内的指令条数过多，比如超过了一级指令缓存的容量；或者需要频繁调用某些函数，而这些函数距离其调用地址的距离过大，超出了 L1 的容量，那么就会频繁发生缓存冲突，引发从 L2 中调取数据的过程，从而降低了程序的运行时间。如果频繁调用的函数比较小，存在一个叫做“内联”的技术可以解决这个问题。这个编译优化会展开频繁调用的小函数，比如如下代码：

```cpp
for (int i = 0; i < n; ++i) x[i] = max(a[i], b[i]) + min(c[i], d[i]);
```

如果我们不使用内联技术，那么如果 min 和 max 函数的地址距离我们这段代码过远，然后恰好和当前的 for 循环的代码相冲突，那么调用一次 min、max 函数就可能导致缓存失配进而导致 CPU 花费过多的时间在等待缓存的刷新，从而降低我们程序的运行效率。但是如果我们改成这样：

```cpp
for (int i = 0; i < n; ++i)
{
    auto mx = a[i] > b[i] ? a[i] : b[i]; // 就是 max 函数做的事情
    auto mn = c[i] < d[i] ? c[i] : d[i]; // 就是 min 函数做的事情
    x[i] = mx + mn;
}
```

那么就不存在频繁调用函数的问题，也自然解决了可能出现的频繁刷新指令缓存的事情。我们为函数添加 `inline`标记后（或者打开`-O3`编译参数，编译器会自己决定是否需要内联），就可以建议编译器展开内联函数从而减少可能的跳转。

减少跳转指令的另一个好处是能够加快流水线的执行。CPU 流水线在遇到跳转后就要重新加载流水线导致 CPU 空载的时间变长，所以如果能够减少跳转指令的数目就能够提升 CPU 流水线的效率。当然现代 CPU 都有分支预测，能够大幅度缓解跳转指令带来的流水线刷新（虽然预测失败后可能要回退操作）所带来的性能损失。



除了解决函数调用带来的跳转指令，循环也是跳转指令的重灾区。显然每一次循环结束后我们都要进行条件跳转，因此小循环的跳转指令的执行时间就会在整个循环执行时间中占相当一部分，如果能解决这个问题就很好。显然我们有解决方案，就是展开循环。比如我们有一个小循环（比如语句不超过10个，几乎没有条件判断），而且执行次数还很少且**固定**（比如不超过几十次），我们可以通过编译期就展开循环从而消去跳转指令：

```cpp
for (int i = 1; i < 64; ++i) s[i] = s[i - 1] + a[i];
```

展开后如下：

```cpp
s[1] = s[0] + a[1];
s[2] = s[1] + a[2];
...
s[63] = s[62] + s[63];
```

这样我们就消去了跳转指令从而提升了流水线的效率。



## 多线程

多线程开发可以充分利用一颗处理器的所有核心的计算资源。同时因为线程之间的内存共享，所有计算任务之间的数据传递十分方便。

### OpenMP

​	OpenMP是共享存储体系结构上的一个并行编程模型。适合于SMP共享内存多处理系统和多核处理器体系结构。利用 `#pragma` 实现对 C/C++ 语言级扩展，并且跨平台，可扩展性好。OpenMP采用 Fork-Join 并行执行方式，简单来说，就是程序主线程执行到并行块时，进入并行执行模式，并行块执行完成后回到串行执行



​	下面是一个计算 π 的程序，原理是：

$$\int_0^1 \frac{4}{1+x^2}\text{d}x\approx\frac{1}{n}\sum_{i=1}^n\frac{4}{i+\left(\frac{i+0.5}{n}\right)^2}$$

```cpp
#include <stdio.h>

const long num_steps = 100000; // 区间数

int main()
{
    double sum = 0.0;
    double step = 1.0 / num_steps;
    clock_t start_time = clock();
    for (int i = 0; i < num_steps; ++i) {
        double x = (i + 0.5) * step;
        sum += 4.0 / (1.0 + x * x);
    }
    clock_t end_time = clock();
    printf("Pi=%f\nRunning time %f\n", step * sum, (double)(end_time - start_time));
    return 0; // I have seen dozens of people missed this statement, which is really stupid. If you missed that in other functions and compile it with -O2, you would be sorry.
}
```

经过 OpenMP 优化后得到：

```cpp
#include <omp.h>
#include <stdio.h>

const int NUM_THREADS = 4; // CPU 核心数
const long num_steps = 1000000000;

int main()
{
    double sum = 0.0;
    double step = 1.0 / num_steps;
    omp_set_num_threads(NUM_THREADS); // 设置线程数
    double start_time = omp_get_wtime();
    #pragma omp parallel for reduction(+:sum)
    for (int i = 0; i < num_steps; ++i) {
        double x = (i + 0.5) * step;
        sum += 4.0 / (1.0 + x * x);
    }
    double end_time = omp_get_wtime();
    printf("Pi=%.12lf\nRunning time %f\n", step * sum, end_time - start_time);
    return 0;
}
```

​	你可以通过 `g++ -fopenmp main.cpp -o main` 来编译这个程序，你还可以注释掉 `#pragma` 子句来看看运行的时间有什么区别（记得把 NUM_THREADS 改成你的电脑的 CPU 额的物理核心数，而不是逻辑核心数）。

注意区别：

1. `#pragma omp` 表示一条 OpenMP 的编译指令，`for`表示现在将`for`循环拆成多个块（可以通过`schedule`参数调整分块方式）分配到多个线程执行，`parallel`表示将并行化修饰的语句的执行，`reduction(+:sum)`表示`sum`的值由每个线程的部分`sum`求和得到

2. 我们将计时用的 `clock` 函数换成了`omp_get_wtime`，是因为`clock`计算的是 CPU 时间，如果程序运行时有多个线程，那么多个线程的 CPU 时间会累积到一起。而我们的计时显然不希望这样算，因此换成`omp_get_wtime`获取系统时间。

3. 我们手动限制了线程数，而不用默认设置，是因为 CPU 包含超线程技术，该技术使得 CPU 的一个核心能同时执行 2~4 个线程，从而提升 CPU 硬件的利用率。从系统的表现来看就是任务管理器中看到的框框数是 CPU 宣称的核心数的 2~4 倍，比如 i7-4790K 宣称其核心数为 4，线程数为 8，所以任务管理器中能看到 8 个框框（可能需要调整 CPU 占用情况的显示方式），但物理核心只有 4 个。然后我们的 OpenMP 程序是计算密集型的，因此不会出现 CPU 一核有难多核围观的情况，会直接占满 CPU 的所有计算资源，而开启超线程后一个核心执行多个线程还会导致访存问题。因为一个核心执行的多个线程的缓存存储在该核心的高速缓存中，如果每个线程访存都不连续，那么高速缓存就被切成了 4 份，相当于降低了缓存的容量从而降低访存效率。

4. 本实例还挺简单的。更多的问题还有，比如同时对一个内存进行修改操作。比如我们现在有多个线程要维护 sum 变量（假设我们没有 reduction 子句），那么两个线程同时修改一个变量会发生什么呢？就是执行 `sum = sum + i` 的时候，我们需要先得到 sum 的值，然后再写入。假设现在有两个线程，一个加 1，一个加 2。执行过程是：线程 1 读 sum，线程 2 读 sum，线程 1 写 sum，线程 2 写 sum。如果一开始 sum = 0，那么 sum 的值最后就为 2 而不是 3。因为线程 2 读 sum 在线程 1 写 sum 之前，所以线程 2 不知道 1 修改了 sum，那么回写 sum 的时候就把线程 1 的值给覆盖掉了。所以就有原子操作和锁的产生。这个问题普遍存在于多线程程序中。

5. `gcc -fopenmp` 参数即可编译 OpenMP 程序。


```cpp
                    计算 1/4 的 num_steps 计算任务
main -> 计算 step -> 计算 1/4 的 num_steps 计算任务 -> 求和 -> 输出
	                计算 1/4 的 num_steps 计算任务
	                计算 1/4 的 num_steps 计算任务
```

​	程序的运行流程如上。简单来说程序的执行和原来串行执行的代码没什么两样。但是我们现在让部分循环并行计算了。这个 OpenMP 用起来很方便很直观。



### 自己实现一个

​	OpenMP 这么好，我想自己造一个超级基本的轮子！比如我们可以做一个：

```cpp
double sum = multithreading::create<int, double>([](int i) {
    double x = (i + 0.5) * step;
    return 4.0 / (1.0 + x * x);
}).thread(4).range(0, num_steps, 1).sum();
```

利用 `<thread>` 库还是很好实现的，上述文字中使用了 C++ 11 的 lambda 表达式语法。

你可以比较一下 OpenMP 和自己实现的速度比较，**请务必打开 `O2` 优化**，因为我这里大量使用了 C++ 标准模板库，不打开 O2 的话 STL 的性能开销很大。如果编译时 omp 系列函数发生链接错误，是因为你没有打开 `-fopenmp`（Visual Studio 默认已经链接 OpenMP，所以不需要额外处理）

```cpp
#include <functional>
#include <algorithm>
#include <vector>
#include <iostream>
#include <thread>
#include <memory>
#include <cstdio>
#include <omp.h>
using namespace std;

const int NUM_THREADS = 4; // CPU 核心数
const long num_steps = 100000000;

namespace multithreading
{
	template <typename LoopT, typename ResultT>
	struct scheduler
	{
		typedef LoopT loop_t;
		typedef ResultT result_t;

		scheduler() {}

		scheduler(loop_t l, loop_t r, loop_t step)
			: l(l), r(r), step(step) {}

		scheduler<loop_t, result_t> for_thread(int thId, int thNum)
		{
			loop_t w = (r - l) / thNum;
			return scheduler(l + w * thId, min(l + w * (thId + 1), r), step);
		}

		result_t loop(function<result_t(result_t, result_t)> reduction, function<result_t(loop_t)> computeFn)
		{
			result_t res = result_t();
			for (loop_t i = l; i < r; i += step)
				res = reduction(res, computeFn(i));
			return res;
		}

		loop_t l, r, step;
	};

	template <typename LoopT, typename ResultT>
	struct work_thread
	{
		typedef LoopT loop_t;
		typedef ResultT result_t;

		work_thread(function<result_t(loop_t)> computeFn, function<result_t(result_t, result_t)> reduction, scheduler<loop_t, result_t> sch)
			: result(), th([&, sch, reduction, computeFn]() mutable {
			result = sch.loop(reduction, computeFn);
		}) {} // 我在写 lambda 表达式时因为忘记写 mutable 被坑了好久 QwQ

		thread th;
		result_t result;

		void join() { th.join(); }
	};

	template <typename LoopT, typename ResultT>
	struct worker
	{
		typedef LoopT loop_t;
		typedef ResultT result_t;

		worker(function<result_t(loop_t)> computeFn) : computeFn(computeFn)
		{
		}

		worker<LoopT, ResultT> &range(LoopT l, LoopT r, LoopT step)
		{
			sch = scheduler<loop_t, result_t>(l, r, step);
			return *this;
		}

		worker<LoopT, ResultT> &thread(int num_threads)
		{
			this->num_threads = num_threads;
			return *this;
		}

		result_t compute(function<result_t(result_t, result_t)> reduction)
		{
			vector<unique_ptr<work_thread<loop_t, result_t>>> threads;
			for (int i = 0; i < num_threads; ++i)
				threads.push_back(make_unique<work_thread<loop_t, result_t>>(computeFn, reduction, sch.for_thread(i, num_threads)));

			result_t res = result_t();
			for (int i = 0; i < num_threads; ++i)
			{
				threads[i]->join();
				res = reduction(threads[i]->result, res);
			}
			return res;
		}

		result_t sum()
		{
			return compute([](result_t a, result_t b) { return a + b; });
		}

	private:
		int num_threads = 0;
		scheduler<loop_t, result_t> sch;
		function<result_t(loop_t)> computeFn;
	};

	template <typename LoopT, typename ResultT>
	worker<LoopT, ResultT> create(function<ResultT(LoopT)> work)
	{
		return worker<LoopT, ResultT>(work);
	}
} // namespace multithreading

int main()
{
	double step = 1.0 / num_steps;

	{
		omp_set_num_threads(NUM_THREADS); // 设置线程数
		double start_time = omp_get_wtime();
        double sum = 0;
#pragma omp parallel for reduction(+:sum)
		for (int i = 0; i < num_steps; ++i)
		{
			double x = (i + 0.5) * step;
			sum += 4.0 / (1.0 + x * x);
		}
		double end_time = omp_get_wtime();
		printf("Pi=%.12f\n Running time %f\n", step * sum, end_time - start_time);
	}

	{
		double start_time = omp_get_wtime();
		double sum = multithreading::create<int, double>([=](int i) {
			double x = (i + 0.5) * step;
			return 4.0 / (1.0 + x * x);
		}).thread(4).range(0, num_steps, 1).sum();
		double end_time = omp_get_wtime();

		printf("Pi=%.12f\n Running time %f\n", step * sum, end_time - start_time);
	}

	return 0;
}
```





## 多进程

​	假设我现在有多台计算机来完成进行计算任务。那应该怎么办呢？情况完全不一样了。首先内存不是共享的，我不能直接访问另一台计算机的内存，除非我通过网络向对方要到数据。所以多进程应用还涉及到网络通信。不过 MPI 需要配环境所以这里就不讲了（逃）